{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "TuningMLP3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFiAqyPL1I1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d012b609-af91-4103-ab2f-3ccddb3b284e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#!/usr/bin/python\n",
        "#read data set to be used\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#load dataset\n",
        "\n",
        "dataset=pd.read_csv('drive/MyDrive/Colab Notebooks/Data/datafinal.csv')\n",
        "dataset['timeIndex']= (dataset['newTime']+1)/288"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (133) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA8NjkzxfCYz"
      },
      "source": [
        "Generate price clasess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaRGjhYj1I1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10c2578-db84-4f3b-ab66-a0388ce32187"
      },
      "source": [
        "dataset['classes']= pd.cut(dataset['rrp_x'],bins=[-1000,25,70,15001],include_lowest=True,right=False, labels=['vl','normal','high'])\n",
        "#generate onehot encoder\n",
        "\n",
        "data_encoded1=pd.get_dummies(dataset['classes'],prefix='PriceQLD')\n",
        "print(data_encoded1.columns)\n",
        "datasetfinal=pd.concat([dataset,data_encoded1],axis=1)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['PriceQLD_vl', 'PriceQLD_normal', 'PriceQLD_high'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DqUExGPvjm7"
      },
      "source": [
        "SELECT VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvu5K9_G1I1v"
      },
      "source": [
        "#generate x and y\n",
        "#y will be the price\n",
        "\n",
        "y= datasetfinal.loc[:,datasetfinal.columns.isin(['PriceQLD_vl', 'PriceQLD_normal', 'PriceQLD_high'])]\n",
        "\n",
        "x= datasetfinal.loc[:,datasetfinal.columns.isin(['PriceQLD_vl', 'PriceQLD_normal', 'PriceQLD_high','timeIndex','month','day_of_week','rrp_y','RMNSW','totaldemand_y','initialsupply_x','dispatchablegeneration_x','netinterchange_x'])]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huq8EBEErhCc"
      },
      "source": [
        "FUNCTION FOR DIVISION IN TEST AND TRAIN SAMPLES, THE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp3szsdr1I1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83c58d8-242b-40b0-e5f7-9c0f8e1af704"
      },
      "source": [
        "\n",
        "def train_test_split(x,y, n_test):\n",
        "\treturn x[:-n_test], x[-n_test:],y[:-n_test],y[-n_test:]\n",
        "1\n",
        "2\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b24XSE9xrYQQ"
      },
      "source": [
        "DIVISION IN TEST AND TRAIN SAMPLES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANonnSR91I1v"
      },
      "source": [
        "n_test=80000\n",
        "X_train, X_test, Y_train, Y_test=train_test_split(x,y, n_test)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGtCAliK6fPF"
      },
      "source": [
        "n= time horizon\n",
        "neurons= number of neurons in hiddent layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVX48Fgl1I1w"
      },
      "source": [
        "#n=[6]\n",
        "n=[6]\n",
        "neurons=[150]\n",
        "#n=[2,3]\n",
        "#neurons=[10,20]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aQ_AFueqf4d"
      },
      "source": [
        "ROBUST SCALER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tjg7DMA1I1w"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "# The values of the quantile range need to be tuned for better results\n",
        "scale=RobustScaler(with_centering=False,quantile_range=(0.5,75))\n",
        "scaleX = RobustScaler().fit(X_train)\n",
        "xnorm= scaleX.transform(X_train)\n",
        "#scaleY=RobustScaler().fit(Y_train)\n",
        "import tensorflow as tf\n",
        "y_train = Y_train\n",
        "ytestnorm = Y_test\n",
        "xtestnorm= scaleX.transform(X_test)\n",
        "ynorm=y_train\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxGTCXS5vGFA",
        "outputId": "1a62ea8f-a9a8-498d-c1e3-1487621f3905"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100868, 9)\n",
            "[[[0 0 1]\n",
            "  [0 0 1]]\n",
            "\n",
            " [[0 0 1]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[0 1 0]\n",
            "  [0 0 1]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 1 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[0 1 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[0 1 0]\n",
            "  [0 1 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C36JnG3Ithqw",
        "outputId": "44025222-a5bd-44b4-b1a9-5f9bbc9343ec"
      },
      "source": [
        "print(ynorm)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        PriceQLD_vl  PriceQLD_normal  PriceQLD_high\n",
            "0                 0                0              1\n",
            "1                 0                0              1\n",
            "2                 0                0              1\n",
            "3                 0                0              1\n",
            "4                 0                0              1\n",
            "...             ...              ...            ...\n",
            "100863            0                1              0\n",
            "100864            0                1              0\n",
            "100865            0                1              0\n",
            "100866            0                1              0\n",
            "100867            0                1              0\n",
            "\n",
            "[100868 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emc4B8ODrSf5"
      },
      "source": [
        "SPLIT TIME SEQUENCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STzfcorx1I1x"
      },
      "source": [
        "#do a function to split the time sequence to predict m Dispatch intervals using n samples in the past\n",
        "\n",
        "#do a function to split the time sequence to predict m Dispatch intervals using n samples in the past at each step\n",
        "\n",
        "def split_sequence(xin,yout, n, m):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(yout)):\n",
        "# find the end of this pattern\n",
        "        end_ix = i + n\n",
        "        out_end_ix = end_ix + m \n",
        "# check if we are beyond the sequence\n",
        "        if out_end_ix > len(yout):\n",
        "            break\n",
        "# gather input and output parts of the pattern\n",
        "        seq_x = xin[i:end_ix]\n",
        "        seq_y=yout[end_ix:out_end_ix]\n",
        "\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLWO1sHnvrqK"
      },
      "source": [
        "ITERATE THROUGH DIFFERENT VARIABLES AND TRAIN AND TEST NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nofrtjsY68mF",
        "outputId": "87921dbe-b70b-4bd7-843d-654af2e6e9a3"
      },
      "source": [
        "from numpy import array\n",
        "\n",
        "recallV=list()\n",
        "misclasV=list()\n",
        "for i in n:\n",
        "  for j in neurons:\n",
        "    print(xnorm.shape)\n",
        "    Xtrain2, ytrain2 = split_sequence(xnorm,ynorm,i,1)\n",
        "    print(ytrain2)\n",
        "    Xtestf, ytestf = split_sequence(xtestnorm,ytestnorm,i,1)\n",
        "    print(ytrain2.shape)\n",
        "    from keras.layers import Dense\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dropout\n",
        "    import tensorflow as tf\n",
        "    import keras as ks\n",
        "    n_input = Xtrain2.shape[1] * Xtrain2.shape[2]\n",
        "    ny=ytrain2.shape[1] * ytrain2.shape[2]\n",
        "    X = Xtrain2.reshape(Xtrain2.shape[0],n_input)\n",
        "    ytrain3=ytrain2.reshape(ytrain2.shape[0], ny)\n",
        "    optimizer = ks.optimizers.Adagrad(lr=0.01)\n",
        "    from keras.callbacks import ReduceLROnPlateau\n",
        "    from keras.callbacks import EarlyStopping\n",
        "    callbackEarlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.95,\n",
        "                              patience=5, min_lr=0.0000001,verbose=1)\n",
        "    # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(j, activation='relu', input_dim=n_input))\n",
        "    model.add(Dropout(0.12))\n",
        "    model.add(Dense(j, activation='relu'))\n",
        "    model.add(Dropout(0.12))\n",
        "    #model.add(Dense(j, activation='relu'))\n",
        "    #model.add(Dropout(0.12))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X, ytrain3,epochs=1054,batch_size=512,shuffle=False,validation_split=0.2,callbacks=[reduce_lr,callbackEarlyStop], verbose=2)\n",
        "    \n",
        "\n",
        "\n",
        "   \n",
        "    print(X_test.shape)\n",
        "    print(Y_test.shape)\n",
        "    \n",
        "    n_input2 = Xtestf.shape[1] * Xtestf.shape[2]\n",
        "\n",
        "    Xtestf= Xtestf.reshape(Xtestf.shape[0], n_input2)\n",
        "    ytestf=ytestf.reshape(ytestf.shape[0], ny)\n",
        "    yhat = model.predict(Xtestf, verbose=0)\n",
        "    ypred=yhat[:,0]\n",
        "    ytestf2=ytestf[:,0]\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    print(confusion_matrix(ytestf.argmax(axis=1),yhat.argmax(axis=1) ))\n",
        "    from sklearn.metrics import recall_score\n",
        "    print('recall', recall_score( ytestf.argmax(axis=1), yhat.argmax(axis=1),average=None))\n",
        "    recallV.append(recall_score(  ytestf.argmax(axis=1), yhat.argmax(axis=1),average=None))\n",
        "    from sklearn.metrics import zero_one_loss\n",
        "  #misclasV=[misclasV zero_one_loss(Y_testNP.argmax(axis=1), ypredNP.argmax(axis=1))]\n",
        "    print('misclass',zero_one_loss(ytestf.argmax(axis=1), yhat.argmax(axis=1)))\n",
        "    misclasV.append(zero_one_loss( ytestf.argmax(axis=1), yhat.argmax(axis=1)))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "print('recall',recallV)\n",
        "print('misclassification',misclasV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100868, 12)\n",
            "[[[0 0 1]]\n",
            "\n",
            " [[0 1 0]]\n",
            "\n",
            " [[0 1 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 1 0]]\n",
            "\n",
            " [[0 1 0]]\n",
            "\n",
            " [[0 1 0]]]\n",
            "(100862, 1, 3)\n",
            "Epoch 1/1054\n",
            "158/158 - 2s - loss: 0.6831 - accuracy: 0.8111 - val_loss: 0.3674 - val_accuracy: 0.8809\n",
            "Epoch 2/1054\n",
            "158/158 - 1s - loss: 0.4123 - accuracy: 0.8833 - val_loss: 0.2826 - val_accuracy: 0.9075\n",
            "Epoch 3/1054\n",
            "158/158 - 1s - loss: 0.3610 - accuracy: 0.8920 - val_loss: 0.2553 - val_accuracy: 0.9150\n",
            "Epoch 4/1054\n",
            "158/158 - 1s - loss: 0.3755 - accuracy: 0.8977 - val_loss: 0.2446 - val_accuracy: 0.9161\n",
            "Epoch 5/1054\n",
            "158/158 - 1s - loss: 0.3290 - accuracy: 0.8994 - val_loss: 0.2424 - val_accuracy: 0.9168\n",
            "Epoch 6/1054\n",
            "158/158 - 1s - loss: 0.3196 - accuracy: 0.9019 - val_loss: 0.2380 - val_accuracy: 0.9174\n",
            "Epoch 7/1054\n",
            "158/158 - 1s - loss: 0.3118 - accuracy: 0.9025 - val_loss: 0.2367 - val_accuracy: 0.9184\n",
            "Epoch 8/1054\n",
            "158/158 - 1s - loss: 0.3057 - accuracy: 0.9037 - val_loss: 0.2328 - val_accuracy: 0.9189\n",
            "Epoch 9/1054\n",
            "158/158 - 1s - loss: 0.3021 - accuracy: 0.9035 - val_loss: 0.2320 - val_accuracy: 0.9192\n",
            "Epoch 10/1054\n",
            "158/158 - 1s - loss: 0.2955 - accuracy: 0.9044 - val_loss: 0.2295 - val_accuracy: 0.9201\n",
            "Epoch 11/1054\n",
            "158/158 - 1s - loss: 0.2966 - accuracy: 0.9048 - val_loss: 0.2288 - val_accuracy: 0.9198\n",
            "Epoch 12/1054\n",
            "158/158 - 1s - loss: 0.2941 - accuracy: 0.9050 - val_loss: 0.2274 - val_accuracy: 0.9199\n",
            "Epoch 13/1054\n",
            "158/158 - 1s - loss: 0.2956 - accuracy: 0.9056 - val_loss: 0.2267 - val_accuracy: 0.9203\n",
            "Epoch 14/1054\n",
            "158/158 - 1s - loss: 0.2868 - accuracy: 0.9067 - val_loss: 0.2265 - val_accuracy: 0.9202\n",
            "Epoch 15/1054\n",
            "158/158 - 1s - loss: 0.2884 - accuracy: 0.9060 - val_loss: 0.2263 - val_accuracy: 0.9206\n",
            "Epoch 16/1054\n",
            "158/158 - 1s - loss: 0.2968 - accuracy: 0.9063 - val_loss: 0.2238 - val_accuracy: 0.9214\n",
            "Epoch 17/1054\n",
            "158/158 - 1s - loss: 0.2813 - accuracy: 0.9067 - val_loss: 0.2239 - val_accuracy: 0.9218\n",
            "Epoch 18/1054\n",
            "158/158 - 1s - loss: 0.2844 - accuracy: 0.9063 - val_loss: 0.2233 - val_accuracy: 0.9216\n",
            "Epoch 19/1054\n",
            "158/158 - 1s - loss: 0.2832 - accuracy: 0.9065 - val_loss: 0.2229 - val_accuracy: 0.9213\n",
            "Epoch 20/1054\n",
            "158/158 - 1s - loss: 0.2830 - accuracy: 0.9073 - val_loss: 0.2227 - val_accuracy: 0.9211\n",
            "Epoch 21/1054\n",
            "158/158 - 1s - loss: 0.2816 - accuracy: 0.9067 - val_loss: 0.2219 - val_accuracy: 0.9213\n",
            "Epoch 22/1054\n",
            "158/158 - 1s - loss: 0.2782 - accuracy: 0.9065 - val_loss: 0.2213 - val_accuracy: 0.9216\n",
            "Epoch 23/1054\n",
            "158/158 - 1s - loss: 0.2831 - accuracy: 0.9077 - val_loss: 0.2209 - val_accuracy: 0.9218\n",
            "Epoch 24/1054\n",
            "158/158 - 1s - loss: 0.2796 - accuracy: 0.9070 - val_loss: 0.2206 - val_accuracy: 0.9219\n",
            "Epoch 25/1054\n",
            "158/158 - 1s - loss: 0.2823 - accuracy: 0.9075 - val_loss: 0.2207 - val_accuracy: 0.9218\n",
            "Epoch 26/1054\n",
            "158/158 - 1s - loss: 0.2771 - accuracy: 0.9076 - val_loss: 0.2194 - val_accuracy: 0.9221\n",
            "Epoch 27/1054\n",
            "158/158 - 1s - loss: 0.2792 - accuracy: 0.9072 - val_loss: 0.2200 - val_accuracy: 0.9219\n",
            "Epoch 28/1054\n",
            "158/158 - 1s - loss: 0.2751 - accuracy: 0.9078 - val_loss: 0.2203 - val_accuracy: 0.9214\n",
            "Epoch 29/1054\n",
            "158/158 - 1s - loss: 0.2768 - accuracy: 0.9075 - val_loss: 0.2190 - val_accuracy: 0.9222\n",
            "Epoch 30/1054\n",
            "158/158 - 1s - loss: 0.2739 - accuracy: 0.9076 - val_loss: 0.2184 - val_accuracy: 0.9224\n",
            "Epoch 31/1054\n",
            "158/158 - 1s - loss: 0.2764 - accuracy: 0.9077 - val_loss: 0.2187 - val_accuracy: 0.9218\n",
            "Epoch 32/1054\n",
            "158/158 - 1s - loss: 0.2721 - accuracy: 0.9073 - val_loss: 0.2184 - val_accuracy: 0.9221\n",
            "Epoch 33/1054\n",
            "158/158 - 1s - loss: 0.2747 - accuracy: 0.9081 - val_loss: 0.2187 - val_accuracy: 0.9221\n",
            "Epoch 34/1054\n",
            "158/158 - 1s - loss: 0.2735 - accuracy: 0.9075 - val_loss: 0.2177 - val_accuracy: 0.9230\n",
            "Epoch 35/1054\n",
            "158/158 - 1s - loss: 0.2752 - accuracy: 0.9075 - val_loss: 0.2174 - val_accuracy: 0.9227\n",
            "Epoch 36/1054\n",
            "158/158 - 1s - loss: 0.2705 - accuracy: 0.9080 - val_loss: 0.2173 - val_accuracy: 0.9227\n",
            "Epoch 37/1054\n",
            "158/158 - 1s - loss: 0.2694 - accuracy: 0.9082 - val_loss: 0.2178 - val_accuracy: 0.9227\n",
            "Epoch 38/1054\n",
            "158/158 - 1s - loss: 0.2730 - accuracy: 0.9087 - val_loss: 0.2172 - val_accuracy: 0.9228\n",
            "Epoch 39/1054\n",
            "158/158 - 1s - loss: 0.2704 - accuracy: 0.9077 - val_loss: 0.2172 - val_accuracy: 0.9227\n",
            "Epoch 40/1054\n",
            "158/158 - 1s - loss: 0.2684 - accuracy: 0.9082 - val_loss: 0.2168 - val_accuracy: 0.9225\n",
            "Epoch 41/1054\n",
            "158/158 - 1s - loss: 0.2722 - accuracy: 0.9080 - val_loss: 0.2173 - val_accuracy: 0.9222\n",
            "Epoch 42/1054\n",
            "158/158 - 1s - loss: 0.2687 - accuracy: 0.9077 - val_loss: 0.2165 - val_accuracy: 0.9230\n",
            "Epoch 43/1054\n",
            "158/158 - 1s - loss: 0.2672 - accuracy: 0.9083 - val_loss: 0.2160 - val_accuracy: 0.9229\n",
            "Epoch 44/1054\n",
            "158/158 - 1s - loss: 0.2683 - accuracy: 0.9087 - val_loss: 0.2162 - val_accuracy: 0.9229\n",
            "Epoch 45/1054\n",
            "158/158 - 1s - loss: 0.2658 - accuracy: 0.9083 - val_loss: 0.2162 - val_accuracy: 0.9227\n",
            "Epoch 46/1054\n",
            "158/158 - 1s - loss: 0.2693 - accuracy: 0.9085 - val_loss: 0.2161 - val_accuracy: 0.9229\n",
            "Epoch 47/1054\n",
            "158/158 - 1s - loss: 0.2668 - accuracy: 0.9087 - val_loss: 0.2159 - val_accuracy: 0.9229\n",
            "Epoch 48/1054\n",
            "158/158 - 1s - loss: 0.2668 - accuracy: 0.9081 - val_loss: 0.2158 - val_accuracy: 0.9226\n",
            "Epoch 49/1054\n",
            "158/158 - 1s - loss: 0.2663 - accuracy: 0.9087 - val_loss: 0.2154 - val_accuracy: 0.9230\n",
            "Epoch 50/1054\n",
            "158/158 - 1s - loss: 0.2679 - accuracy: 0.9083 - val_loss: 0.2151 - val_accuracy: 0.9230\n",
            "Epoch 51/1054\n",
            "158/158 - 1s - loss: 0.2642 - accuracy: 0.9091 - val_loss: 0.2150 - val_accuracy: 0.9229\n",
            "Epoch 52/1054\n",
            "158/158 - 1s - loss: 0.2632 - accuracy: 0.9086 - val_loss: 0.2155 - val_accuracy: 0.9228\n",
            "Epoch 53/1054\n",
            "158/158 - 1s - loss: 0.2656 - accuracy: 0.9083 - val_loss: 0.2155 - val_accuracy: 0.9224\n",
            "Epoch 54/1054\n",
            "158/158 - 1s - loss: 0.2673 - accuracy: 0.9083 - val_loss: 0.2150 - val_accuracy: 0.9227\n",
            "Epoch 55/1054\n",
            "158/158 - 1s - loss: 0.2642 - accuracy: 0.9087 - val_loss: 0.2147 - val_accuracy: 0.9231\n",
            "Epoch 56/1054\n",
            "158/158 - 1s - loss: 0.2633 - accuracy: 0.9083 - val_loss: 0.2149 - val_accuracy: 0.9226\n",
            "Epoch 57/1054\n",
            "158/158 - 1s - loss: 0.2626 - accuracy: 0.9090 - val_loss: 0.2147 - val_accuracy: 0.9230\n",
            "Epoch 58/1054\n",
            "158/158 - 1s - loss: 0.2634 - accuracy: 0.9092 - val_loss: 0.2144 - val_accuracy: 0.9229\n",
            "Epoch 59/1054\n",
            "158/158 - 1s - loss: 0.2653 - accuracy: 0.9085 - val_loss: 0.2142 - val_accuracy: 0.9229\n",
            "Epoch 60/1054\n",
            "158/158 - 1s - loss: 0.2632 - accuracy: 0.9085 - val_loss: 0.2144 - val_accuracy: 0.9231\n",
            "Epoch 61/1054\n",
            "158/158 - 1s - loss: 0.2613 - accuracy: 0.9091 - val_loss: 0.2145 - val_accuracy: 0.9228\n",
            "Epoch 62/1054\n",
            "158/158 - 1s - loss: 0.2636 - accuracy: 0.9082 - val_loss: 0.2148 - val_accuracy: 0.9224\n",
            "Epoch 63/1054\n",
            "158/158 - 1s - loss: 0.2623 - accuracy: 0.9090 - val_loss: 0.2141 - val_accuracy: 0.9228\n",
            "Epoch 64/1054\n",
            "158/158 - 1s - loss: 0.2613 - accuracy: 0.9091 - val_loss: 0.2142 - val_accuracy: 0.9225\n",
            "Epoch 65/1054\n",
            "158/158 - 1s - loss: 0.2614 - accuracy: 0.9098 - val_loss: 0.2139 - val_accuracy: 0.9229\n",
            "Epoch 66/1054\n",
            "158/158 - 1s - loss: 0.2627 - accuracy: 0.9093 - val_loss: 0.2142 - val_accuracy: 0.9230\n",
            "Epoch 67/1054\n",
            "158/158 - 1s - loss: 0.2590 - accuracy: 0.9088 - val_loss: 0.2141 - val_accuracy: 0.9229\n",
            "Epoch 68/1054\n",
            "158/158 - 1s - loss: 0.2617 - accuracy: 0.9088 - val_loss: 0.2138 - val_accuracy: 0.9226\n",
            "Epoch 69/1054\n",
            "158/158 - 1s - loss: 0.2608 - accuracy: 0.9086 - val_loss: 0.2137 - val_accuracy: 0.9227\n",
            "Epoch 70/1054\n",
            "158/158 - 1s - loss: 0.2601 - accuracy: 0.9092 - val_loss: 0.2139 - val_accuracy: 0.9231\n",
            "Epoch 71/1054\n",
            "158/158 - 1s - loss: 0.2612 - accuracy: 0.9091 - val_loss: 0.2135 - val_accuracy: 0.9227\n",
            "Epoch 72/1054\n",
            "158/158 - 1s - loss: 0.2603 - accuracy: 0.9094 - val_loss: 0.2139 - val_accuracy: 0.9229\n",
            "Epoch 73/1054\n",
            "158/158 - 1s - loss: 0.2602 - accuracy: 0.9093 - val_loss: 0.2136 - val_accuracy: 0.9229\n",
            "Epoch 74/1054\n",
            "158/158 - 1s - loss: 0.2592 - accuracy: 0.9099 - val_loss: 0.2132 - val_accuracy: 0.9230\n",
            "Epoch 75/1054\n",
            "158/158 - 1s - loss: 0.2585 - accuracy: 0.9089 - val_loss: 0.2137 - val_accuracy: 0.9231\n",
            "Epoch 76/1054\n",
            "158/158 - 1s - loss: 0.2590 - accuracy: 0.9088 - val_loss: 0.2137 - val_accuracy: 0.9229\n",
            "Epoch 77/1054\n",
            "158/158 - 1s - loss: 0.2589 - accuracy: 0.9093 - val_loss: 0.2135 - val_accuracy: 0.9230\n",
            "Epoch 78/1054\n",
            "158/158 - 1s - loss: 0.2602 - accuracy: 0.9088 - val_loss: 0.2132 - val_accuracy: 0.9229\n",
            "Epoch 79/1054\n",
            "158/158 - 1s - loss: 0.2599 - accuracy: 0.9096 - val_loss: 0.2132 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.009499999787658453.\n",
            "Epoch 80/1054\n",
            "158/158 - 1s - loss: 0.2584 - accuracy: 0.9093 - val_loss: 0.2133 - val_accuracy: 0.9234\n",
            "Epoch 81/1054\n",
            "158/158 - 1s - loss: 0.2574 - accuracy: 0.9097 - val_loss: 0.2134 - val_accuracy: 0.9230\n",
            "Epoch 82/1054\n",
            "158/158 - 1s - loss: 0.2594 - accuracy: 0.9090 - val_loss: 0.2134 - val_accuracy: 0.9232\n",
            "Epoch 83/1054\n",
            "158/158 - 1s - loss: 0.2576 - accuracy: 0.9091 - val_loss: 0.2131 - val_accuracy: 0.9233\n",
            "Epoch 84/1054\n",
            "158/158 - 1s - loss: 0.2568 - accuracy: 0.9090 - val_loss: 0.2134 - val_accuracy: 0.9233\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.009024999709799886.\n",
            "Epoch 85/1054\n",
            "158/158 - 1s - loss: 0.2578 - accuracy: 0.9088 - val_loss: 0.2133 - val_accuracy: 0.9233\n",
            "Epoch 86/1054\n",
            "158/158 - 1s - loss: 0.2577 - accuracy: 0.9097 - val_loss: 0.2132 - val_accuracy: 0.9232\n",
            "Epoch 87/1054\n",
            "158/158 - 1s - loss: 0.2597 - accuracy: 0.9088 - val_loss: 0.2131 - val_accuracy: 0.9236\n",
            "Epoch 88/1054\n",
            "158/158 - 1s - loss: 0.2563 - accuracy: 0.9095 - val_loss: 0.2131 - val_accuracy: 0.9234\n",
            "Epoch 89/1054\n",
            "158/158 - 1s - loss: 0.2571 - accuracy: 0.9091 - val_loss: 0.2129 - val_accuracy: 0.9234\n",
            "Epoch 90/1054\n",
            "158/158 - 1s - loss: 0.2585 - accuracy: 0.9090 - val_loss: 0.2131 - val_accuracy: 0.9233\n",
            "Epoch 91/1054\n",
            "158/158 - 1s - loss: 0.2583 - accuracy: 0.9092 - val_loss: 0.2128 - val_accuracy: 0.9234\n",
            "Epoch 92/1054\n",
            "158/158 - 1s - loss: 0.2583 - accuracy: 0.9100 - val_loss: 0.2131 - val_accuracy: 0.9233\n",
            "Epoch 93/1054\n",
            "158/158 - 1s - loss: 0.2571 - accuracy: 0.9097 - val_loss: 0.2129 - val_accuracy: 0.9235\n",
            "Epoch 94/1054\n",
            "158/158 - 1s - loss: 0.2582 - accuracy: 0.9092 - val_loss: 0.2129 - val_accuracy: 0.9234\n",
            "Epoch 95/1054\n",
            "158/158 - 1s - loss: 0.2574 - accuracy: 0.9092 - val_loss: 0.2130 - val_accuracy: 0.9232\n",
            "Epoch 96/1054\n",
            "158/158 - 1s - loss: 0.2564 - accuracy: 0.9097 - val_loss: 0.2129 - val_accuracy: 0.9234\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.008573750033974648.\n",
            "Epoch 97/1054\n",
            "158/158 - 1s - loss: 0.2565 - accuracy: 0.9095 - val_loss: 0.2129 - val_accuracy: 0.9233\n",
            "Epoch 98/1054\n",
            "158/158 - 1s - loss: 0.2568 - accuracy: 0.9104 - val_loss: 0.2131 - val_accuracy: 0.9233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDuL1vl1I12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78c4b06-4ff3-40b6-c97c-a673b8dc333a"
      },
      "source": [
        " print(yhat.argmax(axis=1) )\n",
        " confusion_matrix(ytestf.argmax(axis=1),yhat.argmax(axis=1) )\n",
        "print('recall', recall_score( ytestf.argmax(axis=1), yhat.argmax(axis=1),average=None))\n",
        "print('misclass',zero_one_loss(ytestf.argmax(axis=1), yhat.argmax(axis=1)))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 1 1]\n",
            "recall [0.54682384 0.96043016 0.78464339]\n",
            "misclass 0.07588069105182893\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}